#!/bin/bash

# Script test HDFS + Spark integration
# KhÃ´ng liÃªn quan Ä‘áº¿n HiBench

set -e

echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "  ğŸ§ª TEST HDFS + SPARK INTEGRATION"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo ""

# Kiá»ƒm tra containers
echo "1ï¸âƒ£  Kiá»ƒm tra containers..."
if ! docker ps | grep -q "spark-master"; then
    echo "âŒ Spark Master khÃ´ng cháº¡y!"
    echo "   Cháº¡y: make start"
    exit 1
fi

if ! docker ps | grep -q "namenode"; then
    echo "âŒ Hadoop NameNode khÃ´ng cháº¡y!"
    echo "   Cháº¡y: make start"
    exit 1
fi

echo "âœ… Táº¥t cáº£ containers Ä‘ang cháº¡y"
echo ""

# Táº¡o thÆ° má»¥c test trÃªn HDFS
echo "2ï¸âƒ£  Táº¡o thÆ° má»¥c /test/ trÃªn HDFS..."
docker exec namenode hdfs dfs -mkdir -p /test 2>/dev/null || true
docker exec namenode hdfs dfs -chmod 777 /test
echo "âœ… ThÆ° má»¥c Ä‘Ã£ sáºµn sÃ ng"
echo ""

# Upload file test lÃªn HDFS
echo "3ï¸âƒ£  Upload file test lÃªn HDFS..."
echo "   - File: sample-data.txt"
echo "   - Destination: hdfs://namenode:9000/test/"

# Copy file vÃ o container trÆ°á»›c
docker cp test/sample-data.txt namenode:/tmp/sample-data.txt

# Upload lÃªn HDFS
docker exec namenode hdfs dfs -put -f /tmp/sample-data.txt /test/

# Kiá»ƒm tra file Ä‘Ã£ upload
echo ""
echo "   ğŸ“ Kiá»ƒm tra file trÃªn HDFS:"
docker exec namenode hdfs dfs -ls /test/
echo ""

FILE_SIZE=$(docker exec namenode hdfs dfs -du -h /test/sample-data.txt | awk '{print $1" "$2}')
echo "   âœ… File Ä‘Ã£ upload thÃ nh cÃ´ng! (Size: $FILE_SIZE)"
echo ""

# Copy Python script vÃ o Spark container
echo "4ï¸âƒ£  Chuáº©n bá»‹ Spark job..."
docker cp test/test-hdfs-spark.py spark-master:/tmp/test-hdfs-spark.py
echo "âœ… Script Ä‘Ã£ sáºµn sÃ ng"
echo ""

# Cháº¡y Spark job
echo "5ï¸âƒ£  Cháº¡y Spark job Ä‘á»ƒ Ä‘á»c vÃ  phÃ¢n tÃ­ch file..."
echo ""
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

docker exec spark-master spark-submit \
    --master spark://spark-master:7077 \
    --deploy-mode client \
    --driver-memory 1g \
    --executor-memory 2g \
    --executor-cores 2 \
    /tmp/test-hdfs-spark.py

echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo ""
echo "ğŸ‰ Test hoÃ n táº¥t!"
echo ""
echo "ğŸ“Š Báº¡n cÃ³ thá»ƒ xem thÃªm:"
echo "   - Spark Master UI:  http://localhost:8080"
echo "   - Spark App UI:     http://localhost:4040"
echo "   - Hadoop HDFS UI:   http://localhost:9870"
echo ""
echo "ğŸ§¹ Äá»ƒ dá»n dáº¹p test data:"
echo "   docker exec namenode hdfs dfs -rm -r /test"
echo ""

